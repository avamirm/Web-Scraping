{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping and Introductory Data Analysis\n",
    "bla bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Web Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEB_URL = \"https://etherscan.io/txs\"\n",
    "TRX_TABLE_XPATH_HEAD = \"//table[@class='table table-hover table-align-middle mb-0']/thead/tr/th\"\n",
    "TRX_TABLE_XPATH_BODY = \"//table[@class='table table-hover table-align-middle mb-0']/tbody/tr\"\n",
    "ETHER_SCAN_CSV_FILE = \"etherscan.csv\"\n",
    "NUM_OF_BLOCKS = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by initializing a WebDriver using Selenium. Specifically, we use the Firefox WebDriver to instantiate a Firefox browser instance. This WebDriver will facilitate interactions with web elements. The WebDriver navigates to the [Etherscan.io](https://etherscan.io/txs).  \n",
    "An assertion is used to verify that the title of the webpage contains the keyword \"Ethereum\". This step ensures that the WebDriver successfully loaded the expected webpage.  \n",
    "Also it is good to mention that the webdriver will wait for a page to load by default via .get() method before attempting to scrape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "def setupWebDriver():\n",
    "    driver.get(WEB_URL)\n",
    "    assert \"Ethereum\" in driver.title\n",
    "\n",
    "setupWebDriver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The getTrxTableHeaders function extracts transactions table headers from HTML source code using the table's id. It modifies the extracted headers to match a specific format and returns the modified header as a list.  \n",
    "The getTrxTableBody function extracts the body of a transaction table from HTML source code using Beautiful Soup. It iterates through each row of the table, extracts the text from each cell, removes newline characters. Additionally, it captures the block number from the first row of the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrxTableHeaders(html_src):\n",
    "    trx_table_head = html_src.find(id = \"ContentPlaceHolder1_theadAllTransactionTable\").find_all('th')\n",
    "    header = [header.get_text().replace(\"\\n\", \"\") for header in trx_table_head]\n",
    "    header[2] = \"Method\"\n",
    "    header.pop(0)\n",
    "    header.pop(5)\n",
    "    header.insert(3, \"Date\")\n",
    "    header.insert(5, \"Local Time\")\n",
    "    header.append(\"Gas Price\")\n",
    "    return header\n",
    "\n",
    "def getTrxTableBody(rows_elements, html_src):\n",
    "    trx_table_body = html_src.find('table')\n",
    "    trx_table_body = trx_table_body.find_all('tr')\n",
    "    block_number = 0\n",
    "    for i in range(1, len(trx_table_body)):\n",
    "        rows = trx_table_body[i].find_all('td')\n",
    "        element = [elem.get_text() for elem in rows]\n",
    "        element = list(map(lambda x: x.replace(\"\\n\", \"\"), element))\n",
    "        element.pop(8)\n",
    "        element.pop(0)\n",
    "        if i == 1:\n",
    "            block_number = int(element[2])\n",
    "        rows_elements.append(element)\n",
    "    return rows_elements, block_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we iterate through the transaction table, continuously fetching data until a certain condition is met. We click on the \"Next\" button in order to implement pagination handling to navigate through the pages and collect the last 10 blocks' transactions data. In this case that certain condition is the block number; At each iteration we get the first row's block number and compare it to the latest block number that we have.  \n",
    "In the end we save the data into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTransactionsToDp(header, body):\n",
    "    transactionsDf = pd.DataFrame(body, columns=header)\n",
    "    transactionsDf.to_csv(ETHER_SCAN_CSV_FILE, mode='a', header=False, index=False)\n",
    "    return transactionsDf\n",
    "    \n",
    "def scrapeWebPage():\n",
    "    html_src = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    header = getTrxTableHeaders(html_src)\n",
    "    rows_elements = []\n",
    "    body, latest_block_number = getTrxTableBody(rows_elements, html_src)\n",
    "    while True:\n",
    "        html_src = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        body, block_number = getTrxTableBody(body, html_src)\n",
    "        next_button = driver.find_element(By.XPATH, '//a[@aria-label=\"Next\"]')\n",
    "        next_button.click()\n",
    "        if block_number == latest_block_number - NUM_OF_BLOCKS:\n",
    "            break\n",
    "    transactionsDf = saveTransactionsToDp(header, body)\n",
    "    driver.close()\n",
    "    return latest_block_number, transactionsDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_block_number, transactionsDf = scrapeWebPage()\n",
    "def saveToCsvFile(transactionsDf):\n",
    "    transactionsDf.to_csv(ETHER_SCAN_CSV_FILE, index=False)\n",
    "    \n",
    "saveToCsvFile(transactionsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Transactions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def isConvertibleToNumeric(series):\n",
    "#     try:\n",
    "#         pd.to_numeric(series, errors='coerce')\n",
    "#         series\n",
    "#     except ValueError:\n",
    "#         return False\n",
    "\n",
    "# def convertDataTypesToNumerical(transactionsDf):\n",
    "#     # transactionsDf = transactionsDf[transactionsDf['Value'].str.contains(' ETH')]\n",
    "#     # transactionsDf['Value'] = transactionsDf['Value'].str.replace(' ETH', '')\n",
    "#     if not isConvertibleToNumeric(transactionsDf['Block']):\n",
    "#         del transactionsDf['Block']\n",
    "#     if not isConvertibleToNumeric(transactionsDf['Value']):\n",
    "#         del transactionsDf['Value']\n",
    "#     if not isConvertibleToNumeric(transactionsDf['Txn Fee']):\n",
    "#         del transactionsDf['Txn Fee']\n",
    "    \n",
    "#     # return transactionsDf\n",
    "\n",
    "# def cleanData(transactionsDf, latest_block_number):\n",
    "#     display(transactionsDf.tail())\n",
    "#     transactionsDf.drop_duplicates(keep='first', inplace=True)\n",
    "#     display(transactionsDf.tail())\n",
    "#     convertDataTypesToNumerical(transactionsDf)\n",
    "#     transactionsDf.query('Block > @latest_block_number - @NUM_OF_BLOCKS & Block <= @latest_block_number', inplace=True)\n",
    "\n",
    "# cleanData(transactionsDf, latest_block_number)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
